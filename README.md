# DataScience-Reference-Repository
View all valued references that I have came across and have used to enhance my knowledge and understanding of various DataScience Cocenpts

* [Getting Started with  Machine Learning](#get-started-with-machine-learning)
* [Popular Algorithms in  Machine Learning](#popular-algorithms-in-machine-learning)
* [Introduction to Deep Learning Algorithms](#introduction-to-deep-learning-algorithms)
* [Reinforcement Learning / Robotics](#reinforcement-learning-robotics)
* [DataScience Courses that would add Value to your understanding](#valuable-courses-for-indepth-insights)
* [Datascience Blogs to BINGE on ](#blogs-to-binge-on)
* [Popular Python Libraries for Data Science](#popular-python-libraries-for-data-science)
* [Deep Learning Research Papers](#deep-learning-research-papers)


## Get started with Machine Learning

Datascience is made up of 3 modules 
* 1)Artificial Intelligence 
* 2)Machine Learning
* 3)Deep Learning . 

AI being the bigger umbrella incorporates everything that a machine (i.e. computers) do to mimic human like behavior.
Machine Learning is a subfield of Artificial Intelligence .Machine Learning becoming a buzz word in the IT industry, it's almost impossible to think of a industry that doesnt need intelligent solutions by adapting to Machine Learning paradigm. 
Here I put forward my own experience , the direction in which I preferred learning the subject in a way to make it more easy and convenient  for anyone who is interested in knowing "How Machines Learn ?? "

1) Lets get started with standard  Wikipedia definition of Machine learning, ML is a *field of computer science that gives computers the ability to learn without being explicitly programmed*. 
To get understanding of how Machines Learn and how Machine Learning paradigm is different from regular programming paradigm , I would recommend the audience to go through the below references . 

	*  [A Friendly Intro to Machine Learning](https://www.youtube.com/watch?v=IpGxLWOIZy4): Introductory video helping you understand Machine Learning
	* [Machine Learning Introduction](https://www.youtube.com/watch?v=seG9J49bBYI): A video that gets you introduced with ML terminologies and concise appropriate definitions 
	* [What is Machine Learning?](https://www.youtube.com/watch?v=WXHM_i-fgGo): This video introduces you to prominent different ways in which we can make Machines learn , viz. Supervised Learning, UnSupervised Learning , Reinforcement Learning (Adaptive Learning)
	* [Basic Machine Learning Algorithms Overview](https://www.youtube.com/watch?v=ggIk08PNcBo): This video gives insights to different algorithms used for different use cases in Machine Learning
	* [Machine Learning from Zero to Hero](https://medium.freecodecamp.org/machine-learning-how-to-go-from-zero-to-hero-40e26f8aa6da): This video is quite interesting in gaining interest in the subject of Machine Learning. 
	
	
## Popular Algorithms in Machine Learning

1) **Linear Regression**: 
	* [Coursera Course - Linear Regression with One Variable](https://www.youtube.com/watch?v=kHwlB_j7Hkc)
	* [Simple Linear Regression](https://www.youtube.com/watch?v=ZkjP5RJLQF4)
	* [Linear Regression for Machine Learning](https://machinelearningmastery.com/linear-regression-for-machine-learning/)

2) **Decision Trees**:
	* [Nando de Freitas Lecture](https://www.youtube.com/watch?v=-dCtJjlEEgM)
	* [Decision Trees in ML](https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052)
	
3)	**Random Forest**:
	* [Nando de Freitas Lecture](https://www.youtube.com/watch?v=3kYujfDgmNk)
	* [Random Forest in ML](https://towardsdatascience.com/understanding-random-forest-58381e0602d2)
	
4) **Logistic Regression**: 
	* [Coursera Course - Logistic Regression and Classification](https://www.youtube.com/watch?v=-la3q9d7AKQ)
	* [Logistic Regression - An Introduction](https://www.youtube.com/watch?v=zAULhNrnuL4)
	* [Stanford Logistic Regression Overview](http://ufldl.stanford.edu/tutorial/supervised/LogisticRegression/)
	* [Siraj Raval Logistic Regression Tutorial](https://www.youtube.com/watch?v=D8alok2P468)

5) **K Nearest Neighbors**: 
	* [K Nearest Neighbors](https://www.youtube.com/watch?v=k_7gMp5wh5A)
	* [GeeksForGeeks Explanation](https://www.geeksforgeeks.org/k-nearest-neighbours/)
	* [Udacity Explanation of KNNs](https://www.youtube.com/watch?v=mpU84OJ5vdQ)

6)  **Support Vector Machine**: 
	* [Support Vector Machine by Instructor Patrick Winston](https://www.youtube.com/watch?v=_PwhiWxHK8o)
	* [Analytics Vidhya Explanation](https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/)
	* [SVM Explanation on scikit learn ](https://scikit-learn.org/stable/modules/svm.html)

		
7) **K-Means**: 
	* [Coursera Course - K Means](https://www.youtube.com/watch?v=hDmNF9JG3lo)
	* [Stanford K Means Overview](http://stanford.edu/~cpiech/cs221/handouts/kmeans.html)
	* [Siraj Raval K Means Tutorial](https://www.youtube.com/watch?v=9991JlKnFmk)
	
## Introduction to Deep Learning Algorithms	

1) **Neural Networks**: Getting started with Deep learning, Neural Networks Deep Learning is subfield of Machine Learning an advance take on Machine Learning . Learning here happens through layers stacked one after the other constituting to a Neural Network architecture. The whole idea revolves around designing the best Neural Network architecture that leads to highest accuracy and lowest error.
	* [A Friendly Introduction to Deep Learning and Neural Networks](https://www.youtube.com/watch?v=BR9h47Jtqyw)
	* [3Blue1Brown Neural Network Playlist](https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)
	* [How Deep Neural Networks Work](https://www.youtube.com/watch?v=ILsA4nyG7I0)
	* [Neural Network Playground](http://playground.tensorflow.org)
	* [Michael Nielsen Book on NNs](http://neuralnetworksanddeeplearning.com/chap1.html)
	

2) **Artificial Neural Networks**:  Artificial Neural Network(CNN) take inspiration from a section in the human brain named temporal Lobe (responsible for storing all your memories for long), ANN learn inherent Latent patterns in data and memorize them during training to recall them later to gice predictions for upcoming data
	* [Neural Nets](https://www.youtube.com/watch?v=uXt8qF2Zzfo): in this video, Prof. Winston introduces neural nets and back propagation.
	* [How Deep Neural Networks Work:Brandon Rohrer](https://www.youtube.com/watch?v=ILsA4nyG7I0)
	* [Gradient Descent:Kilian Weinberger ](https://www.youtube.com/watch?v=o6FfdP2uYh4)
	
	
3) **Convolutional Neural Networks**:  Convolutional Neural Network(CNN) take inspiration from a section in the human brain named Ocipital Lobe (responsible for vision), CNN hence is very popularly used in image processing i.e. unstructured data processing.
	* [CS231n Visual Recognition](http://cs231n.github.io/convolutional-networks/)
	* [CS231n Video Lectures](https://www.youtube.com/playlist?list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC)
	* [Brandon Rohrer YouTube Tutorial](https://www.youtube.com/watch?v=FmpDIaiMIeA)
	* [Andrew Ng's CNN Course](https://www.youtube.com/playlist?list=PLBAGcD3siRDjBU8sKRk0zX9pMz9qeVxud)

4) **Recurrent Neural Networks**: Recurrent Neural Network are Neural Network that are recursive by nature .
	* [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
	* [CS 224D Video Lectures](https://www.youtube.com/playlist?list=PLCJlDcMjVoEdtem5GaohTC1o9HTTFtK7_)
	* [RNNs and LSTMs](https://www.youtube.com/watch?v=WCUNPb-5EYI)
	* [Recurrent Neural Networks - Intel Nervana](https://www.youtube.com/watch?v=Ukgii7Yd_cU)
	* [Introduction to RNNs](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/)

## Reinforcement Learning Robotics

* [End-to-end training of deep visuomotor policies (2016), S. Levine et al.](https://arxiv.org/pdf/1504.00702.pdf)
* [Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection (2016), S. Levine et al.](https://arxiv.org/pdf/1603.02199.pdf)
* [Asynchronous methods for deep reinforcement learning (2016), V. Mnih et al.](http://proceedings.mlr.press/v48/mniha16.pdf)
* [Deep Reinforcement Learning with Double Q-Learning (2016), H. Hasselt et al.](https://arxiv.org/pdf/1509.06461.pdf)
* [Mastering the game of Go with deep neural networks and tree search (2016), D. Silver et al.](https://www.nature.com/articles/nature16961)
* [Continuous control with deep reinforcement learning (2015), T. Lillicrap et al.](https://arxiv.org/pdf/1509.02971.pdf)
* [Deep learning for detecting robotic grasps (2015), I. Lenz et al.](http://www.cs.cornell.edu/~asaxena/papers/lenz_lee_saxena_deep_learning_grasping_ijrr2014.pdf)
* [Playing atari with deep reinforcement learning (2013), V. Mnih et al.](https://arxiv.org/pdf/1312.5602.pdf)


## Valuable Courses for Indepth Insights

* [The Elements of Statistical Learning, Second Edition By Trevor Hastie, Robert Tibshirani, and Jerome Friedman, Springer](https://web.stanford.edu/~hastie/Papers/ESLII.pdf)
* [Applied Data Science with Python Specialization By Christopher Brooks, Kevyn Collins-Thompson, V. G. Vinod Vydiswaran, and Daniel Romero, University of Michigan/Coursera](https://www.coursera.org/specializations/data-science-python)
* [Data Science: Foundations using R Specialization By Jeff Leek, Brian Caffo, and Roger Peng, Johns Hopkins/Coursera](https://www.coursera.org/specializations/data-science-foundations-r)
* [Deep Learning By Andrew Ng, Kian Katanforoosh, and Younes Bensouda Mourri, Stanford/deeplearning.ai/Coursera](https://www.coursera.org/specializations/deep-learning)
* [Fundamentals of Machine Learning By Jeff Prosise, Wintellectnow](https://www.wintellectnow.com/Videos/Watch?videoId=fundamentals-of-machine-learning)
* [Machine Learning By Andrew Ng, Stanford/Coursera](https://www.coursera.org/learn/machine-learning)
* [Machine Learning By Carlos Guestrin and Emily Fox , University of Washington/Coursera](https://www.coursera.org/specializations/machine-learning)
* [Stanford CS 231N](https://www.youtube.com/watch?v=g-PvXUjD6qg&list=PLlJy-eBtNFt6EuMxFYRiNRS07MCWN5UIA) - CNNs
* [Stanford CS 224D](https://www.youtube.com/watch?v=sU_Yu_USrNc&list=PLTuSSFCVeNVCXL0Tak5rJ83O-Bg_ajO5B) - Deep Learning for NLP
* [Hugo Larochelle's Neural Networks Course](https://www.youtube.com/watch?v=SGZ6BttHMPw&list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH)
* [David Silver's Reinforcement Learning Course](https://www.youtube.com/watch?v=2pWv7GOvuf0&list=PL5X3mDkKaJrL42i_jhE4N-p6E2Ol62Ofa)
* [Andrew Ng Machine Learning Course](https://www.coursera.org/learn/machine-learning)
* [Stanford CS 229](https://www.youtube.com/playlist?list=PLA89DCFA6ADACE599) - Pretty much the same as the Coursera course
* [UC Berkeley Kaggle Decal](https://kaggledecal.github.io/)
* [Short MIT Intro to DL Course](https://www.youtube.com/playlist?list=PLkkuNyzb8LmxFutYuPA7B4oiMn6cjD6Rs)
* [Udacity Deep Learning](https://www.udacity.com/course/deep-learning--ud730)
* [Deep Learning School Montreal 2016](http://videolectures.net/deeplearning2016_montreal/) and [2017](http://videolectures.net/deeplearning2017_montreal/)
* [Intro to Neural Nets and ML (Univ of Toronto)](http://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/)
* [Deep RL Bootcamp](https://sites.google.com/view/deep-rl-bootcamp/lectures)
* [CMU Neural Networks for NLP](http://www.phontron.com/class/nn4nlp2017/schedule.html)
* [Bay Area Deep Learning School Day 1 2016](https://www.youtube.com/watch?v=eyovmAtoUx0) and [Day 2](https://www.youtube.com/watch?v=9dXiAecyJrY)
* [Introduction to Deep Learning MIT Course](https://www.youtube.com/playlist?list=PLkkuNyzb8LmxFutYuPA7B4oiMn6cjD6Rs)
* [Caltech CS 156 - Machine Learning](https://www.youtube.com/playlist?list=PLD63A284B7615313A)
* [Berkeley EE 227C - Convex Optimization](https://ee227c.github.io/)

## Blogs to BINGE on

* [OpenAI: Discovering and enacting the path to safe artificial general intelligence](https://www.openai.com/blog/)
* [Distill A modern medium for presenting research](https://distill.pub/)
* [Christopher Olah's blog](http://colah.github.io/)
* [Andrej Karpathy](http://karpathy.github.io/)
* [Data Science Central](https://www.datasciencecentral.com/)
* [SmartData Collective](https://www.smartdatacollective.com/)
* [No Free Hunch](https://medium.com/kaggle-blog)
* [Simply Statistics](https://simplystatistics.org/)
* [Datafloq](https://datafloq.com/)
* [Data Science 101](https://101.datascience.community/)
* [Dataconomy](https://dataconomy.com/)
* [Data Science Report](http://starbridgepartners.com/data-science-report/)
* [Google Research](https://research.googleblog.com/)
* [Neil Lawrence](http://inverseprobability.com/blog)
* [Qure.ai](http://blog.qure.ai/)
* [Brandon Amos](http://bamos.github.io/blog/)
* [Denny Britz](http://www.wildml.com/)
* [Moritz Hardt](http://blog.mrtz.org/)
* [Deepmind](https://deepmind.com/blog/)
* [Machine Learning Mastery](http://machinelearningmastery.com/blog/)
* [Smerity](http://smerity.com/articles/articles.html)
* [The Neural Perspective](https://theneuralperspective.com/)
* [Pete Warden](https://petewarden.com/page/2/)
* [Kevin Zakka](https://kevinzakka.github.io/)
* [Thomas Dinsmore](https://thomaswdinsmore.com/)
* [Rohan Varma](http://rohanvarma.me/)
* [Anish Athalye](https://www.anishathalye.com/)
* [Arthur Juliani](https://medium.com/@awjuliani)
* [CleverHans](http://www.cleverhans.io/)
* [Off the Convex Path](http://www.offconvex.org/about/)
* [Sebastian Ruder](http://ruder.io/#open)
* [Berkeley AI Research](http://bair.berkeley.edu/blog/)
* [Facebook AI Research](https://research.fb.com/blog/)
* [Apple Machine Learning Journal](https://machinelearning.apple.com/)
* [Depth First Learning](http://www.depthfirstlearning.com/)
* [The Gradient](https://thegradient.pub/)

## Popular Python Libraries for Data Science

* [Numpy](http://www.numpy.org/)
* [Pandas](http://pandas.pydata.org/)
* [Matplotlib](https://matplotlib.org/)
* [Matplotlib-Pyplot](https://matplotlib.org/api/pyplot_api.html)
* [Different scalers on data](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html)
* [SciPy](https://www.scipy.org/getting-started.html)
* [Sklearn Modules for Data Preprocessing](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)
* [Sklearn utilities to load datasets](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets)
* [Keras: The Python Deep Learning library](https://keras.io/)
* [Keras Text Preprocessing](https://keras.io/preprocessing/text/)
* [Keras Image Preprocessing](https://keras.io/preprocessing/image/)
* [Keras datasets](https://keras.io/datasets/)
* [Scikit-Learn](http://scikit-learn.org/stable/)


## Deep Learning Research Papers:  
Papers that were quite influential in building and improving Deep Learning paradigm 

* [MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications (2017), Andrew G. Howard et al.](https://arxiv.org/pdf/1704.04861.pdf)
* [A Knowledge-Grounded Neural Conversation Model (2017), Marjan Ghazvininejad et al.](https://arxiv.org/pdf/1702.01932.pdf)
* [Evolution Strategies as a Scalable Alternative to Reinforcement Learning (2017), T. Salimans et al.](https://arxiv.org/pdf/1703.03864v1.pdf)
* [Learning to discover cross-domain relations with generative adversarial networks (2017), T. Kim et al.](https://arxiv.org/pdf/1703.05192v1.pdf)
* [PixelNet: Representation of the pixels, by the pixels, and for the pixels (2017), A. Bansal et al.](https://arxiv.org/pdf/1702.06506v1.pdf)
* [Understanding deep learning requires rethinking generalization (2017), C. Zhang et al.](https://arxiv.org/pdf/1611.03530.pdf)
* [Recurrent neural network based language model (2010), T. Mikolov et al.](http://www.fit.vutbr.cz/research/groups/speech/servite/2010/rnnlm_mikolov.pdf)
* [Understanding the difficulty of training deep feedforward neural networks (2010), X. Glorot and Y. Bengio](https://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2010_GlorotB10.pdf)
* [Gradient-based learning applied to document recognition (1998), Y. LeCun et al.](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)
* [Deep voice: Real-time neural text-to-speech (2017), S. Arik et al.](https://arxiv.org/pdf/1702.07825v2.pdf)
* [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)
* [GoogLeNet](https://arxiv.org/pdf/1409.4842v1.pdf)
* [VGGNet](https://arxiv.org/pdf/1409.1556v6.pdf)
* [ZFNet](https://arxiv.org/pdf/1311.2901v3.pdf)
* [ResNet](https://arxiv.org/pdf/1512.03385.pdf)
* [R-CNN](https://arxiv.org/pdf/1311.2524v5.pdf)
* [Fast R-CNN](https://arxiv.org/pdf/1504.08083.pdf)
* [Adversarial Images](https://arxiv.org/pdf/1412.1897.pdf)
* [Generative Adversarial Networks](https://arxiv.org/pdf/1406.2661v1.pdf)
* [Spatial Transformer Networks](https://arxiv.org/pdf/1506.02025.pdf)
* [DCGAN](https://arxiv.org/pdf/1511.06434v2.pdf)
* [Synthetic Gradients](https://arxiv.org/pdf/1608.05343v1.pdf)
* [Memory Networks](https://arxiv.org/pdf/1410.3916v11.pdf)
* [Mixture of Experts](https://arxiv.org/pdf/1701.06538.pdf)
* [Neural Turing Machines](https://arxiv.org/pdf/1410.5401.pdf)
* [Alpha Go](https://storage.googleapis.com/deepmind-media/alphago/AlphaGoNaturePaper.pdf)
* [Atari DQN](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf)
* [Word2Vec](https://arxiv.org/pdf/1310.4546.pdf)
* [GloVe](https://nlp.stanford.edu/pubs/glove.pdf)
* [A3C](https://arxiv.org/pdf/1602.01783v2.pdf)
* [Gradient Descent by Gradient Descent](https://arxiv.org/pdf/1606.04474v1.pdf)
* [Rethinking Generalization](https://arxiv.org/pdf/1611.03530v1.pdf)
* [Densely Connected CNNs](https://arxiv.org/pdf/1608.06993v1.pdf)
* [EBGAN](https://arxiv.org/pdf/1609.03126v1.pdf)
* [Wasserstein GAN](https://arxiv.org/pdf/1701.07875.pdf)
* [Style Transfer](https://arxiv.org/pdf/1603.08155v1.pdf)
* [Pixel RNN](https://arxiv.org/pdf/1601.06759v2.pdf)
* [Dynamic Coattention Networks](https://arxiv.org/pdf/1611.01604v2.pdf)
* [Convolutional Seq2Seq Learning](https://arxiv.org/pdf/1705.03122.pdf)
* [Seq2Seq](https://arxiv.org/pdf/1409.3215.pdf)
* [Dropout](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf)
* [Batch Norm](https://arxiv.org/pdf/1502.03167.pdf)
* [Large Batch Training](https://arxiv.org/pdf/1609.04836.pdf)
* [Transfer Learning](http://papers.nips.cc/paper/5347-how-transferable-are-features-in-deep-neural-networks.pdf)
* [Adam](https://arxiv.org/pdf/1412.6980.pdf)
* [Speech Recognition](https://arxiv.org/pdf/1303.5778.pdf)
* [Relational Networks](https://arxiv.org/pdf/1706.01427.pdf)
* [Influence Functions](https://arxiv.org/pdf/1703.04730.pdf)
* [ReLu](https://arxiv.org/pdf/1611.01491.pdf)
* [Xavier Initialization](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)
* [Saddle Points and Non-convexity of Neural Networks](https://arxiv.org/pdf/1406.2572.pdf)
* [Overcoming Catastrophic Forgetting in NNs](https://arxiv.org/pdf/1612.00796.pdf)
* [Quasi-Recurrent Neural Networks](https://arxiv.org/pdf/1611.01576.pdf)
* [Escaping Saddle Points Efficiently](https://arxiv.org/pdf/1703.00887.pdf)
* [Progressive Growing of GANs](http://research.nvidia.com/sites/default/files/pubs/2017-10_Progressive-Growing-of//karras2017gan-paper.pdf)
* [Attention is All You Need](https://arxiv.org/pdf/1706.03762.pdf)
* [Dynamic Routing Between Capsules](https://arxiv.org/pdf/1710.09829.pdf)
* [Unsupervised Machine Translation with Monolingual Corpora](https://arxiv.org/pdf/1711.00043.pdf)
* [Population Based Training of NN's](https://arxiv.org/pdf/1711.09846.pdf)
* [Learned Index Structures](https://arxiv.org/pdf/1712.01208v1.pdf)
* [Visualizing Loss Landscapes](https://arxiv.org/pdf/1712.09913v1.pdf)
* [DenseNet](https://arxiv.org/pdf/1608.06993.pdf)
* [SqueezeNet](https://arxiv.org/pdf/1602.07360.pdf)
* [WaveNet](https://arxiv.org/pdf/1609.03499.pdf)
* [Hidden Technical Debt in ML Systems](https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf)
* [MobileNets](https://arxiv.org/pdf/1704.04861.pdf)
* [Learning from Imbalanced Data](http://www.ele.uri.edu/faculty/he/PDFfiles/ImbalancedLearning.pdf)


